{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando o arquivo de configuração para a rede:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/diogo/dados_doutorado/converter_COMPASS_HYPO71/config.ini']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('/home/diogo/dados_doutorado/converter_COMPASS_HYPO71/config.ini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procurando os arquivos da picagem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ev_list = []\n",
    "ev_listS = []\n",
    "\n",
    "for root, dirs, files in os.walk(config['NET']['Pasta_Rede']):\n",
    "    for datafile in files:\n",
    "        if datafile.endswith('.pks'):\n",
    "            ev_list.append(os.path.join(root, datafile))\n",
    "ev_listS = sorted(ev_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Número de picagens para a rede:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de arquivos com os eventos para a Rede Cascavel: 4\n"
     ]
    }
   ],
   "source": [
    "print('Número de arquivos com os eventos para a Rede '+config['NET']['Nome_Rede']+': '+str(len(ev_listS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lendo os arquivos com as picagens (.pks):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ev_lines = [[] for x in range(len(ev_listS))]\n",
    "\n",
    "for i,j in enumerate(ev_listS):\n",
    "    with open(j) as inputfile:\n",
    "        for line in inputfile:\n",
    "            ev_lines[i].append(line.strip().split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando as picagens entre P e S:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ev_HYPO_P = [[] for x in range(len(ev_listS))]\n",
    "ev_HYPO_S = [[] for x in range(len(ev_listS))]\n",
    "for i,j in enumerate(ev_lines):\n",
    "    for k,l in enumerate(j):\n",
    "        if l[3] == 'P':\n",
    "            ev_HYPO_P[i].append(l)\n",
    "        else:\n",
    "            ev_HYPO_S[i].append(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando os parâmetros de nome, tempo, polaridade e chegada da onda P:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ev_P_name = [[] for x in range(len(ev_listS))]\n",
    "ev_P_tempo = [[] for x in range(len(ev_listS))]\n",
    "ev_P_pol = [[] for x in range(len(ev_listS))]\n",
    "ev_P_che = [[] for x in range(len(ev_listS))]\n",
    "\n",
    "for i,j in enumerate(ev_HYPO_P):\n",
    "    for k,l in enumerate(j):\n",
    "        ev_P_name[i].append(l[0][2:])\n",
    "        ev_P_tempo[i].append(l[6][2:-4]+'.'+l[6][-4:-2])\n",
    "        if (l[4]) == '+':\n",
    "             ev_P_pol[i].append('U')\n",
    "        elif (l[4]) == '-':\n",
    "             ev_P_pol[i].append('D')\n",
    "        else: \n",
    "             ev_P_pol[i].append(' ')\n",
    "        if (l[5]) == 'i':\n",
    "             ev_P_che[i].append('I')\n",
    "        elif (l[5]) == 'e':\n",
    "             ev_P_che[i].append('E')\n",
    "        else: \n",
    "             ev_P_che[i].append(' ')                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Separando os parâmetros de nome, tempo, polaridade e chegada da onda S:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ev_S_name = [[] for x in range(len(ev_listS))]\n",
    "ev_S_tempo = [[] for x in range(len(ev_listS))]\n",
    "ev_S_pol = [[] for x in range(len(ev_listS))]\n",
    "ev_S_che = [[] for x in range(len(ev_listS))]\n",
    "\n",
    "for i,j in enumerate(ev_HYPO_S):\n",
    "    for k,l in enumerate(j):\n",
    "        ev_S_name[i].append(l[0][2:])\n",
    "        ev_S_tempo[i].append(l[6][12:-4]+'.'+l[6][-4:-2])\n",
    "        if (l[4]) == '+':\n",
    "             ev_S_pol[i].append('U')\n",
    "        elif (l[4]) == '-':\n",
    "             ev_S_pol[i].append('D')\n",
    "        else: \n",
    "             ev_S_pol[i].append(' ')\n",
    "        if (l[5]) == 'i':\n",
    "             ev_S_che[i].append('I')\n",
    "        elif (l[5]) == 'e':\n",
    "             ev_S_che[i].append('E')\n",
    "        else: \n",
    "             ev_S_che[i].append(' ')                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checando para se existem picagens sem o valor dos parâmetros para a onda S:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check_P_S = []\n",
    "\n",
    "for i, j in enumerate(ev_P_name):\n",
    "    check_P_S.append(list(set(j)- set(ev_S_name[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_no_S = [[] for x in range(len(ev_P_name))]\n",
    "\n",
    "for i, j in enumerate(ev_P_name):\n",
    "    try:\n",
    "        list_no_S[i].append(j.index(' '.join(map(str, check_P_S[i]))))\n",
    "    except ValueError:\n",
    "        list_no_S[i].append([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserindo nas picagens que não tem valores para onda S resultados vazios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, j in enumerate(ev_S_name):\n",
    "    if str(list_no_S[i])[1:-1] != '[]':\n",
    "        ev_S_name[i].insert(int(str(list_no_S[i])[1:-1]),'NO')\n",
    "        ev_S_tempo[i].insert(int(str(list_no_S[i])[1:-1]),'NO')\n",
    "        ev_S_pol[i].insert(int(str(list_no_S[i])[1:-1]),'NO')\n",
    "        ev_S_che[i].insert(int(str(list_no_S[i])[1:-1]),'NO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Montando as picagens para o arquivo .INP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pick_INP = [[] for x in range(len(ev_HYPO_P))]\n",
    "\n",
    "for i,j in enumerate(ev_HYPO_P):\n",
    "    for k,l in enumerate(j):\n",
    "        if ev_S_name[i][k] == 'NO':\n",
    "            pick_INP[i].append(ev_P_name[i][k]+ev_P_che[i][k]+'P'+ev_P_pol[i][k]+str(1)+' '+str(ev_P_tempo[i][k]))\n",
    "        else:\n",
    "            pick_INP[i].append(ev_P_name[i][k]+ev_P_che[i][k]+'P'+ev_P_pol[i][k]+str(1)+' '+str(ev_P_tempo[i][k])+'       '+str(ev_S_tempo[i][k])+ev_S_che[i][k]+'S'+ev_S_pol[i][k]+str(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ln_fim = '                 10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,j in enumerate(pick_INP):\n",
    "    j.append(ln_fim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Montando o cabeçalho para o arquivo .INP através do arquivo de configuração:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ln_1 = 'HEAD                     SOME '+config['NET']['Nome_Rede']+' '+config['NET']['Ano_Rede']+' QUAKES'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ln_2 = 'RESET TEST(06)=1.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importanto as coordenadas das estações:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sta_lst = config['STA']['sta_lst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sta_lst = sta_lst.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sta_name = [i.split(',')[0] for i in sta_lst]\n",
    "sta_lat = [i.split(',')[1] for i in sta_lst]\n",
    "sta_lon = [i.split(',')[2] for i in sta_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decdeg2dmsLAT(dd):\n",
    "    is_positive = dd >= 0\n",
    "    dd = abs(dd)\n",
    "    minutes,seconds = divmod(dd*3600,60)\n",
    "    degrees,minutes = divmod(minutes,60)\n",
    "    if is_positive:\n",
    "        return str(\"{0:02.0f}\".format(degrees))+str(\"{0:02.0f}\".format(minutes))+'.'+str(\"{0:02.0f}\".format(seconds))\n",
    "    else:\n",
    "        return str(\"{0:02.0f}\".format(degrees))+str(\"{0:02.0f}\".format(minutes))+'.'+str(\"{0:02.0f}\".format(seconds))+'S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decdeg2dmsLON(dd):\n",
    "    is_positive = dd >= 0\n",
    "    dd = abs(dd)\n",
    "    minutes,seconds = divmod(dd*3600,60)\n",
    "    degrees,minutes = divmod(minutes,60)\n",
    "    if is_positive:\n",
    "        return str(\"{0:03.0f}\".format(degrees))+str(\"{0:02.0f}\".format(minutes))+'.'+str(\"{0:02.0f}\".format(seconds))\n",
    "    else:\n",
    "        return str(\"{0:03.0f}\".format(degrees))+str(\"{0:02.0f}\".format(minutes))+'.'+str(\"{0:02.0f}\".format(seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp_lat = []\n",
    "inp_lon = []\n",
    "\n",
    "for i,j in enumerate(sta_lat):\n",
    "    inp_lat.append(decdeg2dmsLAT(float(j)))\n",
    "    inp_lon.append(decdeg2dmsLON(float(sta_lon[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importanto o modelo de velocidade da onda P:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vel_P = config['MODEL_VEL_P']['P_model_vel']\n",
    "vel_P = vel_P.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "depth_P = config['MODEL_VEL_P']['Depth_model']\n",
    "depth_P = depth_P.split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Montando os parâmetros da fase para o arquivo .INP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phase_par = '   '+config['FASE']['trial_forcal_depth']+'.  '+config['FASE']['distance_km_from_epicenter_1']+'. '+config['FASE']['distance_km_from_epicenter_0']+'. '+config['FASE']['Vp_Vs_ratio']+'    '+config['FASE']['quality_class']+'              1    1         1   11'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando o arquivo .INP através do arquivo de configuração:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/diogo/dados_doutorado/converter_COMPASS_HYPO71/'+config['NET']['Nome_Rede']+'.INP', \"w\") as text_file:\n",
    "    text_file.write(ln_1+'\\n')\n",
    "    text_file.write(ln_2+'\\n')\n",
    "    text_file.write('\\n')\n",
    "    for i,j in enumerate(sta_name):\n",
    "        text_file.write('  '+j+inp_lat[i]+inp_lon[i]+'\\n')\n",
    "    text_file.write('\\n')\n",
    "    for i,j in enumerate(vel_P):\n",
    "        text_file.write(str(\"{0:1.2f}\".format(float(j)))+'   '+str(\"{0:2.1f}\".format(float(depth_P[i])))+'\\n')\n",
    "    text_file.write('\\n')\n",
    "    text_file.write(phase_par+'\\n')\n",
    "    for i,j in enumerate(pick_INP):\n",
    "        for k,l in enumerate(j):\n",
    "            text_file.write(l+'\\n')\n",
    "text_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
