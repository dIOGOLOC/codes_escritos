import time
from tqdm import tqdm
from multiprocessing import Pool
from sklearn import preprocessing

import matplotlib.pyplot as plt
import matplotlib.path as mpath
from matplotlib import cm
from mpl_toolkits.axes_grid1.inset_locator import inset_axes
from matplotlib.ticker import MultipleLocator, FormatStrFormatter,FuncFormatter
from matplotlib.dates import YearLocator, MonthLocator, DayLocator, HourLocator, MinuteLocator, SecondLocator, DateFormatter
import matplotlib.dates as mdates
import matplotlib.gridspec as gridspec
import matplotlib.colors as mcolors

import cartopy.crs as ccrs
import cartopy.feature as cfeature

import obspy as op
from obspy import read,read_inventory, UTCDateTime, Stream, Trace
from obspy.clients.fdsn.client import Client
from obspy.signal.rotate import rotate_ne_rt
from obspy.geodetics import gps2dist_azimuth,kilometers2degrees
from obspy.taup import TauPyModel
from obspy.signal import PPSD

from tslearn.preprocessing import TimeSeriesScalerMeanVariance,TimeSeriesResampler
from tslearn.clustering import TimeSeriesKMeans,silhouette_score
from kneed import KneeLocator
from sklearn.preprocessing import normalize

import shutil
import json
import glob
import os
import numpy as np
from itertools import combinations
import pandas as pd
from scipy.signal import spectrogram, detrend, resample,savgol_filter,decimate,hilbert
from scipy.stats import circmean, circstd

import pyarrow.feather as feather

import datetime

from sklearn.linear_model import LinearRegression,HuberRegressor,TheilSenRegressor


# ===========
# DIRECTORIES
# ===========

## ------------------------
## Directory with waveforms (SeisComP Data Structure)
## The basic directory and file layout is defined as:
## <SDSdir>/Year/NET/STA/CHAN.TYPE/NET.STA.LOC.CHAN.TYPE.YEAR.DAY

RF_DIR = '/home/sysop/dados_posdoc/INVERSAO_CONJUNTA_SOUTH_AMERICA/DATA/BL.PLTB/'

## -----------------------
## Directory of the output (Figures and Feathers file)

PPSD_OUTPUT = '/home/sysop/dados_posdoc/INVERSAO_CONJUNTA_SOUTH_AMERICA/OUTPUT/RF_ANALISYS/'

## ---------------
## MULTIPROCESSING

num_processes = 20











sta_list = sorted(list(set([i.split('/')[-2] for i in glob.glob(RF_DIR+'*_P_R.sac')])))


sta_list


RF_files = sorted(glob.glob(RF_DIR+'*_P_R.sac'))


[normalize(prf[0].data.reshape(1, -1))]


PRF_lst = []

for idx,prf_file in enumerate(RF_files):
    prf = op.read(prf_file)
    
    PRF_dic = {
                'network': prf[0].stats.network,
                'station': prf[0].stats.station,
                'channel': prf[0].stats.channel,
                'raypar': prf[0].stats.sac.user8,
                'sampling_rate': prf[0].stats.sampling_rate,
                'data': [normalize(prf[0].data.reshape(1, -1))],
                'date':UTCDateTime(year=prf[0].stats.sac.nzyear,julday=prf[0].stats.sac.nzjday,hour=prf[0].stats.sac.nzhour,minute=prf[0].stats.sac.nzmin,second=prf[0].stats.sac.nzsec).datetime
                }
    PRF_lst.append(pd.DataFrame.from_dict(PRF_dic))


PRF_df = pd.concat(PRF_lst)


PRF_df['date'] = pd.to_datetime(PRF_df['date'])


PRF_df


# ------------------------------------
# Adjusting arrays to KMeans procedure

# This Scaler removes the median and scales the data according to the quantile range (defaults to IQR: Interquartile Range). 

#data_all = np.array([PRF_df['data'].values]).T
data_all = PRF_df['data'].values
scaler = RobustScaler()
scaler.fit(data_all)
data_scale = scaler.transform(data_all)

X_train = TimeSeriesResampler(sz=len(data_scale[0])).fit_transform(data_scale)


# ------------------------------------
# Elbow KMeans estimation
elbow_data = []
for n_clusters in tqdm(range(1,10,1),total=len(range(1,10,1)),desc='Elbow Method',position=0,leave=False):
            
    km = TimeSeriesKMeans(n_clusters=n_clusters, verbose=False, random_state=0,n_jobs=-1,metric='euclidean',n_init=2,max_iter_barycenter=10)
    y_pred = km.fit_predict(X_train)
    elbow_data.append((n_clusters, km.inertia_))
        
k_range = []
inertias = []
for elb in elbow_data:
    k_range.append(elb[0])
    inertias.append(elb[1])

# ------------------------------------    
# Elbow KMeans estimation
kn = KneeLocator(k_range, inertias,S=2, curve='convex', direction='decreasing')
elbow_point = kn.knee
            
# ------------------------------------
# Elbow KMeans plot
            
fig_elb, ax_elb = plt.subplots(figsize=(10,5))
            
ax_elb.annotate(str(elbow_point), xy=(elbow_point,inertias[k_range.index(elbow_point)]), xytext=(elbow_point+(elbow_point*0.2),inertias[k_range.index(elbow_point)]+(inertias[k_range.index(elbow_point)]*0.2)),arrowprops=dict(arrowstyle='<-',linewidth=1,color='black'))
ax_elb.scatter(elbow_point,inertias[k_range.index(elbow_point)],color='k', marker='X',s=100)
ax_elb.plot(k_range,inertias,color='grey', marker='o', linestyle='dashed',linewidth=2, markersize=5,zorder=-1)
ax_elb.set_title('Elbow KMeans estimation: '+PRF_df['network'].values[0]+'_'+PRF_df['station'].values[0]+'_'+PRF_df['channel'].values[0])
            
# Set ticks and labels on both sides of the y-axis
ax_elb.set_xlim(0,10)
ax_elb.set_ylabel('Inertia')
ax_elb.set_xlabel('Number of clusters')

os.makedirs(PPSD_OUTPUT+'FIGURES/',exist_ok=True)
fig_elb.savefig(PPSD_OUTPUT+'FIGURES/Elbow_'+PRF_df['network'].values[0]+'_'+PRF_df['station'].values[0]+'_'+PRF_df['channel'].values[0]+'_plot.png',pad_inches=0.02,dpi=200)



# ------------------------------------
# Euclidean k-means
           
n_clu = elbow_point
km = TimeSeriesKMeans(n_clusters=n_clu, verbose=False, random_state=0,n_jobs=-1,metric='euclidean',n_init=2,max_iter_barycenter=10)
y_pred = km.fit_predict(X_train)
            
PRF_df['k-means'] = y_pred

# ------------------------------------
# Compute the mean Silhouette Coefficient.
sscore = round(silhouette_score(X_train, PRF_df['k-means'], metric="euclidean"),2)
           
################################
##### CREATING THE FIGURE ######
################################
            
fig = plt.figure(figsize=(15,10))
gs = gridspec.GridSpec(3, n_clu,height_ratios=[5,2,0.1])
            
ax_prf = fig.add_subplot(gs[0, :])

# Locator: X & Y
majorY = MultipleLocator(20)
minorY = MultipleLocator(10)   

alpha = 0.75
lw = 0.1

# Plot PRF computed via both methods
for i in PRF_df.iterrows():
    name_PRF = i[1]['network']+'.'+i[1]['station']+'.'+i[1]['channel']		

    ax_prf.plot(range(len(i[1]['data'])), i[1]['data'], color='gray', lw=lw, alpha=alpha)
            
ax_prf.plot(range(len(PRF_df['data'].mean())),PRF_df['data'].mean(), color='k', lw=2,ls='--',label='mean')
ax_prf.text(0.1, 0.9,name_PRF,fontweight='bold', fontsize=15, ha='center',va='center',transform=ax_prf.transAxes)
ax_prf.text(0.9, 0.9,'SS: '+str(sscore)+'\n'+' (n:'+str(PRF_df.shape[0])+')',fontweight='bold', fontsize=12, ha='center',va='center',transform=ax_prf.transAxes)
            
ax_prf.set_ylabel('Amp')
ax_prf.set_xlabel('time after P (s)')
            
# Set limits for x-axes
#ax_prf.set_xlim(0.01,200)
#ax_prf.set_ylim(-200,-50)
            
# Set ticks and labels on both sides of the y-axis
ax_prf.spines['top'].set_linewidth(2)
ax_prf.spines['right'].set_linewidth(2)
ax_prf.spines['bottom'].set_linewidth(2)
ax_prf.spines['left'].set_linewidth(2)
ax_prf.yaxis.set_tick_params(which='both',width=2,labelright=True,left=True,right=True)
ax_prf.xaxis.set_tick_params(which='both',width=2,labeltop=False,labelbottom=True,bottom=True,top=True)
            
ax_prf.yaxis.set_major_locator(majorY)
ax_prf.yaxis.set_minor_locator(minorY)
ax_prf.legend(loc='lower left')

# =======================================================================================================================================

# Get unique k-means
unique_k_means = sorted(PRF_df['k-means'].unique())

# ---------------------
# Adding k_means groups

for k in unique_k_means:
    ax = fig.add_subplot(gs[1, k])
            
    df_k = PRF_df[PRF_df['k-means'] == k]
          
    # Plot PRF computed via both methods
    for i in df_k.iterrows():
        ax.plot(range(len(i[1]['data'])), i[1]['data'], color='gray', lw=lw, alpha=alpha)

    ax.plot(range(len(df_k['data'].mean())),df_k['data'].mean(), color='k',ls='--',lw=2,alpha=0.5,label='mean')
    ax.text(0.5, 0.8,'Cluster %d' % (k + 1)+'\n(n='+str(df_k.shape[0])+'['+str(round((df_k.shape[0]*100)/PRF_df.shape[0]))+'%])',fontweight='bold', fontsize=12, ha='center',transform=ax.transAxes)
            
    #ax.set_xlim(0.01,200)
    #ax.set_ylim(-200,-50)
            
    ax.spines['top'].set_linewidth(2)
    ax.spines['right'].set_linewidth(2)
    ax.spines['bottom'].set_linewidth(2)
    ax.spines['left'].set_linewidth(2)
    ax.xaxis.set_tick_params(width=2)
    ax.yaxis.set_tick_params(width=2)  
            
    ax.yaxis.set_major_locator(majorY)
    ax.yaxis.set_minor_locator(minorY)
    ax.yaxis.set_tick_params(labelright=False,labelleft=False,left=True, right=True)  # Show labels on the right side
    ax.legend(loc='lower left')
            
    if k == unique_k_means[0]:
        ax.yaxis.set_tick_params(labelright=False,labelleft=True,left=True, right=True)  # Show labels on the right side
        ax.set_ylabel('Amp')

    if k == unique_k_means[-1]:
        ax.yaxis.set_tick_params(labelright=True,labelleft=False,left=True, right=True)  # Show labels on the right side
        ax.yaxis.set_label_position("right")
        ax.set_ylabel('Amp')


fig.tight_layout()

# -------------
# Saving FIGURE
os.makedirs(PPSD_OUTPUT+'FIGURES/',exist_ok=True)
fig.savefig(PPSD_OUTPUT+'FIGURES/'+i[1]['network']+'_'+i[1]['station']+'_KMeans.png',pad_inches=0.02,dpi=200)
        
# =======================================================================================================================================
# Saving 
# =======================================================================================================================================
os.makedirs(PPSD_OUTPUT+'FEATHER_FILES/'+i[1]['network']+'_'+i[1]['station'],exist_ok=True)
PRF_df.to_feather(PPSD_OUTPUT+'FEATHER_FILES/'+i[1]['network']+'_'+i[1]['station']+'/df_psd_'+i[1]['network']+'_'+i[1]['station']+'_KMeans.feather') 
        
# ----------------------------------------------------------------------------------------------------------
# Close the figure after savig 
# ----------------------------------------------------------------------------------------------------------                             
                                            
plt.close('all')






