import time
from tqdm import tqdm
from multiprocessing import Pool
from sklearn import preprocessing

import matplotlib.pyplot as plt
import matplotlib.path as mpath
from matplotlib import cm
from mpl_toolkits.axes_grid1.inset_locator import inset_axes
from matplotlib.ticker import MultipleLocator, FormatStrFormatter,FuncFormatter
from matplotlib.dates import YearLocator, MonthLocator, DayLocator, HourLocator, MinuteLocator, SecondLocator, DateFormatter
import matplotlib.dates as mdates
import matplotlib.gridspec as gridspec
import matplotlib.colors as mcolors

import cartopy.crs as ccrs
import cartopy.feature as cfeature

import obspy as op
from obspy import read,read_inventory, UTCDateTime, Stream, Trace
from obspy.clients.fdsn.client import Client
from obspy.signal.rotate import rotate_ne_rt
from obspy.geodetics import gps2dist_azimuth,kilometers2degrees
from obspy.taup import TauPyModel
from obspy.signal import PPSD

from tslearn.preprocessing import TimeSeriesScalerMeanVariance,TimeSeriesResampler
from tslearn.clustering import TimeSeriesKMeans,silhouette_score
from kneed import KneeLocator

import shutil
import json
import glob
import os
import numpy as np
from itertools import combinations
import pandas as pd
from scipy.signal import spectrogram, detrend, resample,savgol_filter,decimate,hilbert
from scipy.stats import circmean, circstd

import pyarrow.feather as feather

import datetime

from sklearn.linear_model import LinearRegression,HuberRegressor,TheilSenRegressor


# ===========
# DIRECTORIES
# ===========

# Periods and psd values for the New Low Noise Model and New High Noise Model.
# For information on New High/Low Noise Model see [Peterson1993]_.

NHNM_MODEL = '/home/sysop/dados_posdoc/PROJETO_RSBR_15_YEARS/NOISE_MODELS/high_noise.npy'
NLNM_MODEL = '/home/sysop/dados_posdoc/PROJETO_RSBR_15_YEARS/NOISE_MODELS/low_noise.npy'
PERIODS_MODEL = '/home/sysop/dados_posdoc/PROJETO_RSBR_15_YEARS/NOISE_MODELS/model_periods.npy'

## ------------------------
## Directory with waveforms (SeisComP Data Structure)
## The basic directory and file layout is defined as:
## <SDSdir>/Year/NET/STA/CHAN.TYPE/NET.STA.LOC.CHAN.TYPE.YEAR.DAY

NPZ_DIR = '/home/sysop/dados_posdoc/PROJETO_RSBR_15_YEARS/OUTPUT/PPSD_NPZ_FILES/'

## -----------------------
## Directory of the output (Figures and Feathers file)

PPSD_OUTPUT = '/home/sysop/dados_posdoc/PROJETO_RSBR_15_YEARS/OUTPUT/PPSD_ANALISYS/'

## ---------------
## MULTIPROCESSING

num_processes = 20











sta_list = sorted(list(set([i.split('/')[-1] for i in glob.glob(NPZ_DIR+'*/*/*')])))


sta_list


psd_files = sorted(glob.glob(NPZ_DIR+'*/*/*/*/*'))


sta_npz_files = []
for sta in sta_list:
    sta_npz_files.append(glob.glob(NPZ_DIR+'*/*/'+sta+'/*/*HHZ*'))


PPSD_lst = []
for npz_f in sta_npz_files[1]:
    dados = PPSD.load_npz(npz_f)
    for idx,psds in enumerate(dados.psd_values):
        if np.mean(psds) > -1000:
            PPSD_dic = {
                'network': dados.network,
                'station': dados.station,
                'channel': dados.channel,
                'psd_values': [dados.psd_values[idx]],
                'current_times_used': dados.current_times_used[idx].datetime,
                'period_bin_centers': [dados.period_bin_centers],
                'date':dados.current_times_used[idx].date
            }
            PPSD_lst.append(pd.DataFrame.from_dict(PPSD_dic))


PPSD_df = pd.concat(PPSD_lst)


PPSD_df['date'] = pd.to_datetime(PPSD_df['date'])


# --------------------------
# Agrupando o Dataframe com os PSDs calculados a cada 1 dia
# Agrupar por dia mantendo as colunas desejadas

df_grouped = PPSD_df.groupby(pd.Grouper(key='date',freq='1D')).agg({
    'psd_values': 'mean',
    'network': 'first',
    'station': 'first',
    'channel': 'first',
    'current_times_used': 'first',
    'period_bin_centers': 'first'})


df_grouped = df_grouped.dropna()


df_grouped['month'] = pd.to_datetime(df_grouped['current_times_used']).dt.strftime('%b')
df_grouped


# ------------------------------------
# Adjusting arrays to KMeans procedure
X_train = TimeSeriesResampler(sz=len(df_grouped['psd_values'].values[0])).fit_transform(df_grouped['psd_values'].values)


# ------------------------------------
# Elbow KMeans estimation
elbow_data = []
for n_clusters in tqdm(range(1,10,1),total=len(range(1,10,1)),desc='Elbow Method',position=0,leave=False):
            
    #km = TimeSeriesKMeans(n_clusters=n_clusters, verbose=False, random_state=0,n_jobs=-1,metric='dtw',n_init=2,max_iter_barycenter=10)
    km = TimeSeriesKMeans(n_clusters=n_clusters, verbose=False, random_state=0,n_jobs=-1,metric='euclidean',n_init=2,max_iter_barycenter=10)
    y_pred = km.fit_predict(X_train)
    elbow_data.append((n_clusters, km.inertia_))
        
k_range = []
inertias = []
for elb in elbow_data:
    k_range.append(elb[0])
    inertias.append(elb[1])

# ------------------------------------    
# Elbow KMeans estimation
kn = KneeLocator(k_range, inertias,S=2, curve='convex', direction='decreasing')
elbow_point = kn.knee
            
# ------------------------------------
# Elbow KMeans plot
            
fig_elb, ax_elb = plt.subplots(figsize=(10,5))
            
ax_elb.annotate(str(elbow_point), xy=(elbow_point,inertias[k_range.index(elbow_point)]), xytext=(elbow_point+(elbow_point*0.2),inertias[k_range.index(elbow_point)]+(inertias[k_range.index(elbow_point)]*0.2)),arrowprops=dict(arrowstyle='<-',linewidth=1,color='black'))
ax_elb.scatter(elbow_point,inertias[k_range.index(elbow_point)],color='k', marker='X',s=100)
ax_elb.plot(k_range,inertias,color='grey', marker='o', linestyle='dashed',linewidth=2, markersize=5,zorder=-1)
ax_elb.set_title('Elbow KMeans estimation: '+PPSD_df['network'].values[0]+'_'+PPSD_df['station'].values[0]+'_'+PPSD_df['channel'].values[0])
            
# Set ticks and labels on both sides of the y-axis
ax_elb.set_xlim(0,10)
ax_elb.set_ylabel('Inertia')
ax_elb.set_xlabel('Number of clusters')

os.makedirs(PPSD_OUTPUT+'PPSD_FIGURES/',exist_ok=True)
fig_elb.savefig(PPSD_OUTPUT+'PPSD_FIGURES/Elbow_'+PPSD_df['network'].values[0]+'_'+PPSD_df['station'].values[0]+'_'+PPSD_df['channel'].values[0]+'_plot.png',pad_inches=0.02,dpi=200)



# ------------------------------------
# Euclidean k-means
           
n_clu = elbow_point
#km = TimeSeriesKMeans(n_clusters=n_clu, verbose=False, random_state=0,n_jobs=-1,metric='dtw')
km = TimeSeriesKMeans(n_clusters=n_clu, verbose=False, random_state=0,n_jobs=-1,metric='euclidean',n_init=2,max_iter_barycenter=10)
y_pred = km.fit_predict(X_train)
            
df_grouped['k-means'] = y_pred

# ------------------------------------
# Compute the mean Silhouette Coefficient.
sscore = round(silhouette_score(X_train, df_grouped['k-means'], metric="euclidean"),2)
           
################################
##### CREATING THE FIGURE ######
################################
            
fig = plt.figure(figsize=(15,10))
gs = gridspec.GridSpec(3, n_clu,height_ratios=[5,2,0.1])
            
ax_psd_HF = fig.add_subplot(gs[0, :])

# Locator: X & Y
majorY = MultipleLocator(20)
minorY = MultipleLocator(10)   

alpha = 0.75
lw = 0.1

# Ordenar os meses cronologicamente
month_order = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',
               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']

# Criar um colormap contínuo e discretizar para 12 meses
cmap = plt.get_cmap("Spectral")
colors = [cmap(i) for i in np.linspace(0, 1, len(month_order))]

# Criar um dicionário de cores associadas aos meses
month_to_color = dict(zip(month_order, colors))

# Criar um colormap discreto
cmap_discrete = mcolors.ListedColormap(colors)

# Criar a normalização correta para a colorbar
norm = mcolors.BoundaryNorm(boundaries=np.arange(len(month_order)+1)-0.5, ncolors=len(month_order))

nlnm_data = np.load(NLNM_MODEL)
model_periods = np.load(PERIODS_MODEL)
nhnm_data = np.load(NHNM_MODEL)

for periods, noise_model in zip((model_periods,model_periods),(nhnm_data,nlnm_data)):
    ax_psd_HF.semilogx(periods, noise_model, '0.4', linewidth=2)

# Plot PSD computed via both methods
for i in df_grouped.iterrows():
    name_PPSD = i[1]['network']+'.'+i[1]['station']+'.'+i[1]['channel']		
    
    month = i[1]['month']
    color = month_to_color[month]
    ax_psd_HF.plot(i[1]['period_bin_centers'], i[1]['psd_values'], color=color, lw=lw, alpha=alpha)
            
ax_psd_HF.semilogx(df_grouped['period_bin_centers'].mean(),df_grouped['psd_values'].mean(), color='k', lw=2,ls='--',label='mean')
ax_psd_HF.text(0.1, 0.9,name_PPSD,fontweight='bold', fontsize=15, ha='center',va='center',transform=ax_psd_HF.transAxes)
ax_psd_HF.text(0.9, 0.9,'SS: '+str(sscore)+'\n'+' (n:'+str(df_grouped.shape[0])+')',fontweight='bold', fontsize=12, ha='center',va='center',transform=ax_psd_HF.transAxes)
            
ax_psd_HF.set_ylabel('Amplitude [$m^2/s^4/Hz$] [dB]')
ax_psd_HF.set_xlabel('Period (s)')
            
# Set limits for x-axes
ax_psd_HF.set_xlim(0.01,200)
ax_psd_HF.set_ylim(-200,-50)
            
# Set ticks and labels on both sides of the y-axis
ax_psd_HF.spines['top'].set_linewidth(2)
ax_psd_HF.spines['right'].set_linewidth(2)
ax_psd_HF.spines['bottom'].set_linewidth(2)
ax_psd_HF.spines['left'].set_linewidth(2)
ax_psd_HF.yaxis.set_tick_params(which='both',width=2,labelright=True,left=True,right=True)
ax_psd_HF.xaxis.set_tick_params(which='both',width=2,labeltop=False,labelbottom=True,bottom=True,top=True)
            
ax_psd_HF.yaxis.set_major_locator(majorY)
ax_psd_HF.yaxis.set_minor_locator(minorY)
ax_psd_HF.legend(loc='lower left')

# =======================================================================================================================================

# Get unique k-means
unique_k_means = sorted(df_grouped['k-means'].unique())

# ---------------------
# Adding k_means groups

for k in unique_k_means:
    ax = fig.add_subplot(gs[1, k])
            
    df_k = df_grouped[df_grouped['k-means'] == k]

    for periods, noise_model in zip((model_periods,model_periods),(nhnm_data,nlnm_data)):
        ax.semilogx(periods, noise_model, '0.4', linewidth=2)

            
    # Plot PSD computed via both methods
    for i in df_k.iterrows():
        month = i[1]['month']
        color = month_to_color[month]
        ax.semilogx(i[1]['period_bin_centers'], i[1]['psd_values'], color=color, lw=lw, alpha=alpha)
    ax.semilogx(df_k['period_bin_centers'].mean(),df_k['psd_values'].mean(), color='k',ls='--',lw=2,alpha=0.5,label='mean')
    ax.text(0.5, 0.8,'Cluster %d' % (k + 1)+'\n(n='+str(df_k.shape[0])+'['+str(round((df_k.shape[0]*100)/df_grouped.shape[0]))+'%])',fontweight='bold', fontsize=12, ha='center',transform=ax.transAxes)
            
    ax.set_xlim(0.01,200)
    ax.set_ylim(-200,-50)
            
    ax.spines['top'].set_linewidth(2)
    ax.spines['right'].set_linewidth(2)
    ax.spines['bottom'].set_linewidth(2)
    ax.spines['left'].set_linewidth(2)
    ax.xaxis.set_tick_params(width=2)
    ax.yaxis.set_tick_params(width=2)  
            
    ax.yaxis.set_major_locator(majorY)
    ax.yaxis.set_minor_locator(minorY)
    ax.yaxis.set_tick_params(labelright=False,labelleft=False,left=True, right=True)  # Show labels on the right side
    ax.legend(loc='lower left')
            
    if k == unique_k_means[0]:
        ax.yaxis.set_tick_params(labelright=False,labelleft=True,left=True, right=True)  # Show labels on the right side
        ax.set_ylabel('Amplitude [$m^2/s^4/Hz$] [dB]')

    if k == unique_k_means[-1]:
        ax.yaxis.set_tick_params(labelright=True,labelleft=False,left=True, right=True)  # Show labels on the right side
        ax.yaxis.set_label_position("right")
        ax.set_ylabel('Amplitude [$m^2/s^4/Hz$] [dB]')

# --------------------
# Adding Time Coverage

for k in unique_k_means:
    df_k = df_grouped[df_grouped['k-means'] == k]
  
    ax = fig.add_subplot(gs[2, k])

    ax.xaxis_date()
    ax.set_yticks([])
    for ik in df_k.iterrows():
        # Get your dates
        start = ik[1]['current_times_used'].date()
        end = start + datetime.timedelta(days=1)  # Add 24 hours
        
        month = ik[1]['month']
        color = month_to_color[month]
    
        # Convert to matplotlib format
    
        start = mdates.date2num(start)
        end = mdates.date2num(end)
        ax.axvspan(start, end, 0, 1, facecolor=color, lw=0)
    ax.set_xlim(mdates.date2num(df_grouped['current_times_used'].min()), mdates.date2num(df_grouped['current_times_used'].max()))

# =======================================================================================================================================

# Create a color bar
# Create a scalar mappable for the colorbar
# Criar a colorbar
sm = plt.cm.ScalarMappable(cmap=cmap_discrete, norm=norm)
cbar = plt.colorbar(sm,ax=ax_psd_HF, ticks=np.arange(len(month_order)))
cbar.set_label('Month')
cbar.set_ticklabels(month_order)
fig.tight_layout()

# -------------
# Saving FIGURE
os.makedirs(PPSD_OUTPUT+'PPSD_FIGURES/',exist_ok=True)
fig.savefig(PPSD_OUTPUT+'PPSD_FIGURES/'+i[1]['network']+'_'+i[1]['station']+'_KMeans.png',pad_inches=0.02,dpi=200)
        
# =======================================================================================================================================
# Saving 
# =======================================================================================================================================
os.makedirs(PPSD_OUTPUT+'FEATHER_FILES/'+i[1]['network']+'_'+i[1]['station'],exist_ok=True)
df_grouped.to_feather(PPSD_OUTPUT+'FEATHER_FILES/'+i[1]['network']+'_'+i[1]['station']+'/df_psd_'+i[1]['network']+'_'+i[1]['station']+'_KMeans.feather') 
        
# ----------------------------------------------------------------------------------------------------------
# Close the figure after savig 
# ----------------------------------------------------------------------------------------------------------                             
                                            
plt.close('all')






